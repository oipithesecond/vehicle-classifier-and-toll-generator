{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95f99c-3d45-4892-8050-22ad9572ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import shutil \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "DATASET_DIR = r\"D:\\sem 5\\DL\\Project\\dataset2\\Trucks\" \n",
    "\n",
    "output_base_dir = r\"D:\\sem 5\\DL\\Project\\dataset2\\Trucks_YOLO\"\n",
    "train_dir = os.path.join(output_base_dir, \"train\")\n",
    "val_dir = os.path.join(output_base_dir, \"val\")\n",
    "\n",
    "# Define subdirectories for images and labels\n",
    "train_images_dir = os.path.join(train_dir, \"images\")\n",
    "train_labels_dir = os.path.join(train_dir, \"labels\")\n",
    "val_images_dir = os.path.join(val_dir, \"images\")\n",
    "val_labels_dir = os.path.join(val_dir, \"labels\")\n",
    "\n",
    "\n",
    "def load_axle_data(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads all .jpg/.JPG/.jpeg/.JPEG/.png/.PNG and .json pairs from the dataset folder.\n",
    "    \"\"\"\n",
    "\n",
    "    image_extensions = ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob.glob(os.path.join(dataset_path, ext)))\n",
    "    print(f\"Found {len(image_paths)} images. Now matching with JSON...\")\n",
    "    dataset = []\n",
    "\n",
    "    loaded_count = 0\n",
    "    missing_json_count = 0\n",
    "    error_loading_count = 0\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        json_path = os.path.join(dataset_path, base_name + \".json\")\n",
    "\n",
    "        if not os.path.exists(json_path):\n",
    "            missing_json_count += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f: \n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_path}: {e}\")\n",
    "            error_loading_count += 1\n",
    "            continue\n",
    "\n",
    "        boxes = []\n",
    "        for ann in data.get(\"shapes\", []):\n",
    "            label = ann.get(\"label\", \"\").strip().lower()\n",
    "            if label != \"axle\":\n",
    "                continue\n",
    "\n",
    "            shape_type = ann.get(\"shape_type\")\n",
    "            points = ann.get(\"points\", [])\n",
    "\n",
    "            if shape_type == \"rectangle\" and len(points) == 2:\n",
    "                x1, y1 = points[0]\n",
    "                x2, y2 = points[1]\n",
    "                xmin = min(x1, x2)\n",
    "                ymin = min(y1, y2)\n",
    "                xmax = max(x1, x2)\n",
    "                ymax = max(y1, y2)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            elif shape_type == \"circle\" and len(points) == 2:\n",
    "                x1, y1 = points[0]\n",
    "                x2, y2 = points[1]\n",
    "                xmin = min(x1, x2)\n",
    "                ymin = min(y1, y2)\n",
    "                xmax = max(x1, x2)\n",
    "                ymax = max(y1, y2)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported or malformed Axle annotation in {json_path}: \"\n",
    "                      f\"Shape={shape_type}, Points={points}\")\n",
    "\n",
    "\n",
    "        # Get image dimensions from JSON\n",
    "        img_width = data.get(\"imageWidth\")\n",
    "        img_height = data.get(\"imageHeight\")\n",
    "\n",
    "        # Basic check if dimensions were found\n",
    "        if not isinstance(img_width, (int, float)) or not isinstance(img_height, (int, float)):\n",
    "             print(f\"Warning: Invalid or missing image dimensions in {json_path}. Width: {img_width}, Height: {img_height}. Skipping.\")\n",
    "             error_loading_count += 1\n",
    "             continue\n",
    "\n",
    "\n",
    "        dataset.append({\n",
    "            \"image_path\": img_path,\n",
    "            \"json_path\": json_path,\n",
    "            \"width\": float(img_width), \n",
    "            \"height\": float(img_height),\n",
    "            \"axles\": boxes\n",
    "        })\n",
    "        loaded_count += 1\n",
    "\n",
    "    print(f\"Finished loading. Successfully processed: {loaded_count}, Missing JSON: {missing_json_count}, Errors/Skipped: {error_loading_count}\")\n",
    "    return dataset\n",
    "\n",
    "def convert_to_yolo(data_list, img_output_dir, lbl_output_dir, class_index=0):\n",
    "    \"\"\" Converts data points to YOLO format and copies images. \"\"\"\n",
    "    count = 0\n",
    "    skipped_no_axles = 0\n",
    "    skipped_dimension_error = 0\n",
    "    skipped_write_error = 0\n",
    "    skipped_copy_error = 0\n",
    "\n",
    "    for item in data_list:\n",
    "        img_path = item['image_path']\n",
    "        img_width = item['width']\n",
    "        img_height = item['height']\n",
    "        axles = item['axles'] \n",
    "\n",
    "        # (double check) if image dimensions are invalid \n",
    "        if not img_width or not img_height or img_width <= 0 or img_height <= 0:\n",
    "            print(f\"Warning: Skipping {os.path.basename(img_path)} due to invalid dimensions W:{img_width} H:{img_height}.\")\n",
    "            skipped_dimension_error += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        base_filename = os.path.basename(img_path)\n",
    "        label_filename = os.path.splitext(base_filename)[0] + \".txt\"\n",
    "        label_filepath = os.path.join(lbl_output_dir, label_filename)\n",
    "\n",
    "        yolo_lines = []\n",
    "        valid_box_found = False\n",
    "        for box in axles:\n",
    "            x1, y1, x2, y2 = box\n",
    "\n",
    "            if x1 >= x2 or y1 >= y2:\n",
    "                print(f\"Warning: Invalid box coordinates {box} in {os.path.basename(item['json_path'])}. Skipping box.\")\n",
    "                continue\n",
    "\n",
    "            # Ensure coordinates are within image bounds (clamp if slightly outside)\n",
    "            x1 = max(0.0, x1)\n",
    "            y1 = max(0.0, y1)\n",
    "            x2 = min(img_width, x2)\n",
    "            y2 = min(img_height, y2)\n",
    "\n",
    "            # Recalculate dimensions after clamping\n",
    "            box_width = x2 - x1\n",
    "            box_height = y2 - y1\n",
    "            center_x = x1 + (box_width / 2)\n",
    "            center_y = y1 + (box_height / 2)\n",
    "\n",
    "            # Check for zero width/height after clamping\n",
    "            if box_width <= 0 or box_height <= 0:\n",
    "                 print(f\"Warning: Box {box} in {os.path.basename(item['json_path'])} has zero width/height after clamping. Skipping box.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            # Normalize coordinates\n",
    "            norm_center_x = center_x / img_width\n",
    "            norm_center_y = center_y / img_height\n",
    "            norm_width = box_width / img_width\n",
    "            norm_height = box_height / img_height\n",
    "\n",
    "            # check normalized values \n",
    "            if not (0 <= norm_center_x <= 1 and 0 <= norm_center_y <= 1 and 0 < norm_width <= 1 and 0 < norm_height <= 1):\n",
    "                 print(f\"Warning: Invalid normalized values for box {box} in {os.path.basename(item['json_path'])}. Skipping box. Values: cx={norm_center_x}, cy={norm_center_y}, w={norm_width}, h={norm_height}\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            yolo_lines.append(f\"{class_index} {norm_center_x:.6f} {norm_center_y:.6f} {norm_width:.6f} {norm_height:.6f}\")\n",
    "            valid_box_found = True \n",
    "\n",
    "\n",
    "        if not valid_box_found:\n",
    "            skipped_no_axles += 1 \n",
    "            continue\n",
    "\n",
    "\n",
    "        # Write YOLO label file\n",
    "        try:\n",
    "            with open(label_filepath, 'w') as f:\n",
    "                f.write(\"\\n\".join(yolo_lines))\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing label file {label_filepath}: {e}\")\n",
    "            skipped_write_error += 1\n",
    "            continue\n",
    "\n",
    "        # Copy image file\n",
    "        try:\n",
    "            dest_img_path = os.path.join(img_output_dir, base_filename)\n",
    "            shutil.copy(img_path, dest_img_path)\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying image file {img_path} to {img_output_dir}: {e}\")\n",
    "            skipped_copy_error += 1\n",
    "            # Clean up label file if image copy failed\n",
    "            if os.path.exists(label_filepath):\n",
    "                 try:\n",
    "                     os.remove(label_filepath)\n",
    "                     print(f\" - Removed corresponding label file {label_filename}\")\n",
    "                 except Exception as rem_e:\n",
    "                     print(f\" - Failed to remove label file {label_filename}: {rem_e}\")\n",
    "\n",
    "\n",
    "    # Report counts after iterating through the list\n",
    "    print(f\" - Processed items: {count}\")\n",
    "    print(f\" - Skipped (no valid axles): {skipped_no_axles}\")\n",
    "    print(f\" - Skipped (dimension error): {skipped_dimension_error}\")\n",
    "    print(f\" - Skipped (label write error): {skipped_write_error}\")\n",
    "    print(f\" - Skipped (image copy error): {skipped_copy_error}\")\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "#create Output Directories\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "print(f\"Ensured YOLO directory structure exists under: {output_base_dir}\")\n",
    "\n",
    "# load the Initial Data\n",
    "axle_dataset = load_axle_data(DATASET_DIR)\n",
    "\n",
    "if axle_dataset:\n",
    "    # split Data\n",
    "    try:\n",
    "        train_data, val_data = train_test_split(\n",
    "            axle_dataset,\n",
    "            test_size=0.2,\n",
    "            random_state=42 \n",
    "        )\n",
    "        print(f\"\\nSplit dataset: {len(train_data)} training, {len(val_data)} validation samples.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during train/test split: {e}\")\n",
    "        print(\"Cannot proceed with conversion. Ensure 'axle_dataset' was loaded correctly.\")\n",
    "        train_data, val_data = [], [] \n",
    "\n",
    "\n",
    "    if train_data:\n",
    "        print(\"\\nConverting training data to YOLO format...\")\n",
    "        train_count = convert_to_yolo(train_data, train_images_dir, train_labels_dir, class_index=0) # Assuming 'axle' is class 0\n",
    "        print(f\"Finished converting training data.\")\n",
    "\n",
    "    if val_data:\n",
    "        print(\"\\nConverting validation data to YOLO format...\")\n",
    "        val_count = convert_to_yolo(val_data, val_images_dir, val_labels_dir, class_index=0) # Assuming 'axle' is class 0\n",
    "        print(f\"Finished converting validation data.\")\n",
    "\n",
    "    #  dataset.yaml file \n",
    "    abs_train_images_dir = os.path.abspath(train_images_dir)\n",
    "    abs_val_images_dir = os.path.abspath(val_images_dir)\n",
    "\n",
    "    # Content for the YAML file\n",
    "    yaml_content = f\"\"\"\n",
    "train: {abs_train_images_dir}\n",
    "val: {abs_val_images_dir}\n",
    "\n",
    "# number of classes\n",
    "nc: 1\n",
    "\n",
    "# class names (index 0 corresponds to 'axle')\n",
    "names: ['axle']\n",
    "\"\"\"\n",
    "\n",
    "    yaml_filepath = os.path.join(output_base_dir, \"dataset.yaml\")\n",
    "    try:\n",
    "        with open(yaml_filepath, 'w') as f:\n",
    "            f.write(yaml_content)\n",
    "        print(f\"\\nCreated dataset configuration file: {yaml_filepath}\")\n",
    "        print(f\"Train path in YAML: {abs_train_images_dir}\")\n",
    "        print(f\"Val path in YAML: {abs_val_images_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError writing dataset.yaml file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n'axle_dataset' is empty. No data loaded, cannot proceed with split and conversion.\")\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8066ab1-a245-47cc-9b09-7214df8bf0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Path to the dataset.yaml \n",
    "yaml_path = r\"D:\\sem 5\\DL\\Project\\dataset2\\Trucks_YOLO\\dataset.yaml\"\n",
    "\n",
    "model_name = 'yolov8n.pt'\n",
    "\n",
    "results_dir = r\"D:\\sem 5\\DL\\Project\\dataset2\\model\"\n",
    "os.makedirs(results_dir, exist_ok=True) \n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"--- Starting YOLOv8 Training ---\")\n",
    "print(f\"Dataset configuration: {yaml_path}\")\n",
    "print(f\"Pre-trained model: {model_name}\")\n",
    "print(f\"Number of epochs: {EPOCHS}\")\n",
    "print(f\"Results will be saved in: {results_dir}\")\n",
    "\n",
    "model = YOLO(model_name)\n",
    "\n",
    "# training\n",
    "results = model.train(\n",
    "    data=yaml_path,        \n",
    "    epochs=EPOCHS,         \n",
    "    imgsz=640,             \n",
    "    project=results_dir,   \n",
    "    name='axle_detection'  \n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "print(f\"Results saved in: {os.path.join(results_dir, 'axle_detection')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8d374-7997-47bf-afaf-368cb46dfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# results.png file \n",
    "results_graph_path = r\"D:\\sem 5\\DL\\Project\\dataset2\\model\\axle_detection\\results.png\"\n",
    "\n",
    "Image(filename=results_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f0b9a-3b03-4331-86ae-adb28b9aa712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\sem 5\\DL\\Project\\dataset2\\Trucks_YOLO\\train\\images\\20170418075806_color-[ROI-1]-27.jpg: 288x640 1 axle, 138.7ms\n",
      "Speed: 5.5ms preprocess, 138.7ms inference, 25.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mD:\\sem 5\\DL\\Project\\dataset2\\runs\\detect\\predict3\u001b[0m\n",
      "Prediction finished. Results saved.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = r\"D:\\sem 5\\DL\\Project\\dataset2\\model\\axle_detection\\weights\\best.pt\"\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "results = model.predict(source=r'D:\\sem 5\\DL\\Project\\dataset2\\Trucks_YOLO\\train\\images\\20170418075806_color-[ROI-1]-27.jpg', save=True)\n",
    "\n",
    "print(\"Prediction finished. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabc81e-dbc3-4420-88f0-86f8e340b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\downloads_2\\photo_2025-10-27_20-02-13 (2).jpg: 384x640 1 axle, 162.0ms\n",
      "Speed: 7.0ms preprocess, 162.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected 1 axles in photo_2025-10-27_20-02-13 (2).jpg\n",
      "Result image saved to: D:\\sem 5\\DL\\Project\\dataset2\\runs\\detect\\photo_2025-10-27_20-02-13 (2).jpg\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "model_path = r'D:\\sem 5\\DL\\Project\\dataset2\\model\\axle_detection\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "test_image_path = r'E:\\downloads_2\\photo_2025-10-27_20-02-13 (2).jpg'\n",
    "output_dir = r'D:\\sem 5\\DL\\Project\\dataset2\\runs\\detect'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results = model(\n",
    "    test_image_path,\n",
    "    conf=0.065,        # low to catch all candidates\n",
    "    iou=0.2          # Increase IoU threshold to merge closer boxes (default = ~0.7)\n",
    ")\n",
    "\n",
    "\n",
    "axle_count = 0\n",
    "img = cv2.imread(test_image_path)\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  \n",
    "    for box in boxes:\n",
    "        # if the detected class index is 0 (axle)\n",
    "        if int(box.cls[0]) == 0:\n",
    "            axle_count += 1\n",
    "            coords = box.xyxy[0].tolist()\n",
    "            coords = [int(c) for c in coords] \n",
    "            x1, y1, x2, y2 = coords\n",
    "\n",
    "            #  confidence score\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            # draw rectangle on the image\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green box, thickness 2\n",
    "            # Add label and confidence\n",
    "            label = f\"Axle: {conf:.2f}\"\n",
    "            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display\n",
    "print(f\"Detected {axle_count} axles in {os.path.basename(test_image_path)}\")\n",
    "\n",
    "# Save the image with boxes drawn\n",
    "output_filename = os.path.basename(test_image_path)\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "cv2.imwrite(output_path, img)\n",
    "print(f\"Result image saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90592235-1264-4292-98ee-be03f3f6de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "DATASET_DIR = r\"D:\\sem 5\\DL\\Project\\dataset2\\Trucks\"\n",
    "\n",
    "# List all image files\n",
    "image_extensions = ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']\n",
    "all_images = []\n",
    "for ext in image_extensions:\n",
    "    all_images.extend(glob.glob(os.path.join(DATASET_DIR, ext)))\n",
    "\n",
    "print(f\"Found {len(all_images)} image files:\")\n",
    "for img in sorted(all_images)[:2000]:  # Show first 20\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e039e-828d-4f22-a60f-699a5cc370fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
